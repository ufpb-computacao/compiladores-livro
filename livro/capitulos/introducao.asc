== Introdução

.Objetivos do capítulo
____________________
Ao final deste capítulo você deverá ser capaz de:

* Entender a função e a estrutura geral de um compilador
* Diferenciar interpretadores de compiladores
* Compreender os motivos por que se estuda os compiladores
____________________

Este capítulo é uma introdução aos compiladores: o que são, para que 
servem, e como são organizados. Também discutimos para quê se aprende 
sobre compiladores e onde esse conhecimento pode ser útil. Compiladores 
são, essencialmente, tradutores de linguagens de programação. Por isso, 
vamos começar a discussão falando sobre linguagens de programação em 
geral. 

=== Linguagens

O que é uma linguagem? Deixamos para os linguistas e filósofos a definição
geral do que vem a ser uma linguagem, nos seus vários sentidos. Aqui nos
preocupamos apenas com as linguagens de programação, e daqui em diante quando se
falar em _linguagem_ será entendido que é uma linguagem de programação; 
quando for preciso tratar de outro tipo de linguagem, isso estará explícito no
texto.

Um _programa_ é uma seqüência de instruções que devem ser executadas por
um computador. Em outras palavras, um programa especifica um algoritmo de 
maneira executável. Uma _linguagem de programação_ é uma notação 
para escrever programas. Enquanto as linguagens naturais, como português,
são notações para comunicação entre pessoas, as linguagens de programação
existem, a princípio, para que o programador comunique ao computador as tarefas 
que devem ser realizadas. A linguagem deve ser, portanto, precisa; o computador 
não pode fazer julgamentos e resolver ambiguidades.  

É importante notar também que um programa é 
freqüentemente um instrumento de comunicação entre programadores: é comum
que um deles tenha que ler e entender programas escritos por outro. Alguns
importantes cientistas da computação, aliás, defendem que a comunicação
entre programadores é o objetivo primário de um programa, a sua execução
sendo praticamente um ``efeito colateral''. Donald Knuth sugeriu que programação
é a arte de dizer a outra pessoa o que se quer que o computador faça. 

É impossível estudar compiladores sem estudar as linguagens de programação. Já
o contrário é possível: podemos estudar linguagens sem conhecer nada sobre 
compiladores. Desta forma, as linguagens se tornam simplesmente notações para
descrever algoritmos -- o que pode ser suficiente para algumas pessoas -- mas em
geral se quer executar esses algoritmos e não apenas descreve-los. Para isso
é necessário ter ao menos um conhecimento mínimo sobre compiladores. Entender
mais do que esse mínimo dá ao programador um maior poder e controle sobre
questões de eficiência dos seus programas. Também é importante para aprender
a usar melhor as linguagens de programação. 

=== O que é um Compilador?

Como vimos, uma linguagem de programação é uma notação para escrever programas. 
Em geral, programas são escritos por pessoas para serem executados por 
computadores. Mas pessoas e computadores funcionam de forma diferente, o que 
leva à existência de linguagens de programação com diferentes _níveis_. Os 
processadores que executam os programas de computador normalmente executam 
instruções simples e elementares. As linguagens de _baixo nível_ são aquelas 
mais próximas das linguagens dos processadores. Essas linguagens, entretanto, 
são consideradas difíceis de programar, devido à grande quantidade de detalhes 
que precisam ser especificados. Assim, algumas linguagens foram criadas para 
tornar mais fácil a tarefa de programação de computadores. Essas linguagens são 
chamadas de linguagens de _alto nível_. 

Para executar programas escritos em uma linguagem de alto nível, entretanto, é 
preciso traduzir esses programas para uma linguagem de baixo nível que possa ser 
executada diretamente por alguma máquina. O programa que faz essa tradução é
chamado de _compilador_. 

Portanto, um compilador é um programa que traduz programas escritos em 
uma linguagem, chamada de _linguagem-fonte_, para outra linguagem,
a _linguagem-destino_. Normalmente, a linguagem-fonte é uma de alto 
nível, e a linguagem de destino é uma linguagem de máquina de algum processador, 
ou algum outro tipo de linguagem de baixo nível que seja executada diretamente 
por uma plataforma existente. O diagrama na Figura <<estrutura>> resume essa 
estrutura básica. 

[[estrutura]]
.Estrutura básica de um compilador.
image::images/introducao/compblock.eps[scaledwidth="70%"]

=== Processadores de Programas: Compiladores, Interpretadores e Máquinas Virtuais

Mais uma vez, um compilador é um tradutor cujo objetivo principal é transformar
um programa para uma forma diretamente executável. Esta não é a única maneira
de executar programas em linguagens de alto-nível: uma alternativa é traduzir
e executar ao mesmo tempo. É o que fazem os _interpretadores_. Um 
interpretador puro tem que analisar e traduzir o programa-fonte toda vez
que ele precisa ser executado. 

[[interpcomp]]
.Fluxo de execução de um interpretador (à esquerda) e de um compilador (à direita).
image::images/introducao/interpcomp.png[scaledwidth="90%"]

Nos sistemas reais, modelos híbridos de interpretação e compilação são comuns.
Por exemplo, o compilador Java +javac+ não traduz os programas em linguagem 
Java para alguma linguagem de máquina de um processador, mas sim para a linguagem 
da máquina virtual Java (JVM), constituída de _bytecodes_. Uma implementação 
simples da JVM roda o programa compilado em _bytecodes_ interpretando-o. 
Atualmente, a maioria das máquinas virtuais Java compilam o programa em 
_bytecode_ para código nativo da máquina onde reside antes de executa-lo,
para melhorar o desempenho. Isso é chamado de compilação _Just In Time_,
ou JIT. Da mesma forma, os interpretadores reais não analisam e traduzem o
programa inteiro em cada execução; os programas são normalmente transformados
para alguma forma intermediária e parcialmente analisados para facilitar sua
execução. Também é comum que mesmo linguagens compiladas para código nativo
tenham um sistema de tempo de execução (_runtime_) que é acoplado aos
programas traduzidos para código de máquina e que, como o nome esclarece,
serve para dar suporte ao programa durante sua execução; desta forma, pode-se
ter um pouco de interpretação envolvida. Com vista nestes fatos, é difícil 
dividir exatamente os compiladores dos interpretadores. Nesta disciplina
consideramos principalmente os compiladores, mas muito do que é estudado serve
também para interpretadores. 

Aqui vale a pena considerar a relação entre o modelo semântico de uma linguagem
de programação e uma máquina virtual. De fato, cada linguagem de programação
pode ser vista como definindo uma máquina virtual que a executa. O modelo
semântico da linguagem é o funcionamento desta máquina. Um interpretador puro
para uma linguagem é uma máquina virtual para ela. Como no estudo da Organização
de Computadores, é necessário organizar as máquinas em camadas. Por isso existe,
em um nível mais baixo, a linguagem de máquina, que define o modelo de execução
do _hardware_ em si; logo acima temos o Sistema Operacional, que define uma 
linguagem com novas primitivas, conhecidas como _chamadas de sistema_.
Acima do SO podemos ter um compilador de linguagem de alto nível que traduz 
diretamente para código nativo, como o compilador C +gcc+; ou podemos ter 
uma máquina virtual que executa diretamente uma linguagem em _bytecode_, 
como é o caso da máquina virtual Java. Acima da JVM temos o compilador 
+javac+, que traduz um programa em Java para sua versão em _bytecode_. 

A definição do que é feito em _software_ e o que é feito em _hardware_ 
não é absoluta, sendo estabelecida por motivos de praticidade, desempenho e 
economia. Poderia se criar um processador que executasse diretamente a linguagem 
C, mas seu projeto seria complicadíssimo e seu custo muito alto. 

=== Aplicações da Tecnologia de Compiladores

Compiladores, ferramentas, análise de entrada. 

////
Verificar repetição aqui. 
////

Portanto, um compilador é um tradutor cujo objetivo principal é transformar
um programa para uma forma diretamente executável. Esta não é a única maneira
de executar programas em linguagens de alto-nível: uma alternativa é traduzir
e executar ao mesmo tempo. É o que fazem os _interpretadores_. Um 
interpretador puro tem que analisar e traduzir o programa-fonte toda vez
que ele precisa ser executado. 

Nos sistemas reais, modelos híbridos de interpretação e compilação são comuns.
Por exemplo, o compilador Java +javac+ não traduz os programas em linguagem 
Java para alguma linguagem de máquina de um processador, mas sim para a linguagem 
da máquina virtual Java (JVM), constituída de _bytecodes_. Uma implementação 
simples da JVM roda o programa compilado em _bytecodes_ interpretando-o. 
Atualmente, a maioria das máquinas virtuais Java compilam o programa em 
_bytecode_ para código nativo da máquina onde reside antes de executa-lo,
para melhorar o desempenho. Isso é chamado de compilação _Just In Time_,
ou JIT. Da mesma forma, os interpretadores reais não analisam e traduzem o
programa inteiro em cada execução; os programas são normalmente transformados
para alguma forma intermediária e parcialmente analisados para facilitar sua
execução. Também é comum que mesmo linguagens compiladas para código nativo
tenham um sistema de tempo de execução (_runtime_) que é acoplado aos
programas traduzidos para código de máquina e que
serve para dar suporte ao programa durante sua execução; desta forma, pode-se
ter um pouco de interpretação envolvida. Com vista nestes fatos, é difícil 
dividir exatamente os compiladores dos interpretadores. Nesta disciplina
consideramos principalmente os compiladores, mas muito do que é estudado serve
também para interpretadores. 

Aqui vale a pena considerar a relação entre o modelo semântico de uma linguagem
de programação e uma máquina virtual. De fato, cada linguagem de programação
pode ser vista como definindo uma máquina virtual que a executa. O modelo
semântico da linguagem é o funcionamento desta máquina. Um interpretador puro
para uma linguagem é uma máquina virtual para ela. Como no estudo da Organização
de Computadores, é necessário organizar as máquinas em camadas. Por isso existe,
em um nível mais baixo, a linguagem de máquina, que define o modelo de execução
do _hardware_ em si; logo acima temos o Sistema Operacional, que define uma 
linguagem com novas primitivas, conhecidas como _chamadas de sistema_.
Acima do SO podemos ter um compilador de linguagem de alto nível que traduz 
diretamente para código nativo, como o compilador C \verb|gcc|; ou podemos ter 
uma máquina virtual que executa diretamente uma linguagem em _bytecode_, 
como é o caso da máquina virtual Java. Acima da JVM temos o compilador 
+javac+, que traduz um programa em Java para sua versão em _bytecode_. 

A definição do que é feito em _software_ e o que é feito em _hardware_ 
não é absoluta, sendo estabelecida por motivos de praticidade, desempenho e 
economia. Poderia se criar um processador que executasse diretamente a linguagem 
C, mas seu projeto seria complicadíssimo e seu custo muito alto. 

=== Organização de um Compilador

Vanguarda e retaguarda, análise e síntese, etapas. 

Na Figura <<estrutura>> a estrutura básica de um compilador é apresentada
de uma forma muito simplificada. Agora consideramos essa estrutura em maiores 
detalhes. Em décadas de desenvolvimento dos compiladores, estabeleceram-se 
algumas tradições na forma de estruturá-los. Uma dessas tradições é separar 
o compilador em duas partes principais: a primeira analisa o programa-fonte para
verificar sua corretude e extrair as informações necessárias para a tradução; a
segunda utiliza as informações coletadas para gerar, ou sintetizar, o programa
na linguagem de destino. É o modelo de análise e síntese; a fase de análise 
também é chamada de vanguarda do compilador (_front-end_) e a de síntese é 
conhecida como retaguarda (_back-end_). Isso é mostrado na Figura <<anlsin>>.

[[anlsin]]
.O modelo de análise e síntese. 
image::images/introducao/anlsin.eps[scaledwidth="70%"]

Na figura, vê-se uma ligação entre as duas partes. O que é transmitido entre a 
análise e a síntese é uma forma chamada de representação intermediária do 
programa. É como se fosse uma linguagem ``a meio caminho'' entre as linguagens
fonte e destino. A representação intermediária é a saída da fase de análise, 
e entrada da fase de síntese. 

Há uma série de razões para dividir os compiladores desta forma. Uma delas
é modularizar a construção dos compiladores: a interface entre análise e síntese
fica bem determinada -- é a representação intermediária. As duas partes ficam
então menos acopladas e mais independentes, podendo ser trocadas sem afetar a 
outra parte, desde que a interface seja mantida. A construção modular reduz o 
custo de suportar várias linguagens fonte e várias linguagens destino: digamos
que seja necessário compilar latexmath:[$M$] linguagens diferentes para 
latexmath:[$N$] arquiteturas; se 
for construído um compilador para cada combinação, serão necessários 
latexmath:[$M \times N$]
compiladores no total. Caso a representação intermediária seja compartilhada,
pode-se escrever apenas latexmath:[$M$] módulos de análise e latexmath:[$N$] 
módulos de síntese, para um esforço total de latexmath:[$M + N$] 
(ao invés de latexmath:[$M \times N$]). Um exemplo dessa técnica é o 
GCC (GNU Compiler Collection), que usa as linguagens intermediárias RTL, GENERIC
e GIMPLE, o que possibilita que os módulos de análise sejam escritos independente
dos módulos de síntese; de fato, o GCC suporta várias linguagens (C, C++, 
Fortran, etc) e gera código para várias arquiteturas (Intel x86, Sparc, MIPS, etc). 

O ideal deste modelo é que a representação intermediária fosse completamente 
independente tanto da linguagem fonte como da linguagem de destino. Neste caso
seria possível ter uma representação intermediária universal, e todos os 
compiladores poderiam utiliza-la: para criar um compilador para uma nova 
linguagem seria necessário apenas escrever o módulo de análise; para 
suportar uma nova arquitetura bastaria escrever um módulo de síntese. Na prática,
entretanto, isto não é possível. Para gerar código de destino com eficiência
aceitável, a representação intermediária de um compilador vai depender tanto
de características da linguagem fonte como da linguagem destino. 

Agora consideramos em mais detalhe o que os módulos de análise e síntese devem
fazer. 

[[estanl]]
.Estrutura do módulo de análise.
image::images/introducao/estanl.eps[scaledwidth="60%"]

A Figura <<estanl>> mostra a estrutura do módulo de análise. O 
programa-fonte é, inicialmente, um conjunto de caracteres; a tarefa da fase
de análise léxica é agrupar esses caracteres em palavras significativas para
a linguagem, ou _tokens_. Em seguida, a análise sintática deve, através
do conjunto e ordem dos _tokens_, extrair a estrutura gramatical do 
programa, que é expressa em uma árvore sintática. A análise semântica, ou
análise contextual, examina a árvore sintática para obter informações de
contexto, adicionando anotações à árvore com estas informações. A fase
final da análise é a transformação da árvore com anotações, resultado
de todas as fases anteriores, no código intermediário necessário para a
síntese. 

[[estsin]]
.Estrutura do módulo de síntese.
image::images/introducao/estsin.eps[scaledwidth="60%"]

O módulo de síntese é detalhado na figura <<estsin>>. Primeiro, o
código intermediário recebido do módulo de análise é otimizado; o objetivo
é tornar o código gerado mais eficiente no uso do tempo e/ou do espaço. Depois,
o código intermediário otimizado é utilizado para gerar código na linguagem
de destino, geralmente a linguagem de máquina de alguma arquitetura. O código 
de destino gerado ainda pode ser passado por mais uma fase de otimização, 
chegando enfim ao código final gerado pelo compilador. Dependendo da 
arquitetura, também pode ser preciso colocar o código final em um formato
adequado para ser executado (não mostrado na figura). 

Existem mais dois componentes dos compiladores que não são fases do módulo
de análise nem do de síntese. Estes são a tabela de símbolos e o sistema de
tempo de execução. A tabela de símbolos é usada por praticamente todas as 
fases do compilador; durante o processamento do programa fonte, muitos 
símbolos -- nomes de variáveis, funções, classes, módulos e outras 
construções da linguagem -- são definidos e referenciados. A tabela de 
símbolos guarda as informações sobre cada um deles (por exemplo, o tipo
de um símbolo que é o nome de uma variável). O sistema de tempo 
de execução, como já mencionado, é composto por vários serviços que existem
para suportar a execução dos programas gerados. Um exemplo de tarefa realizada
pelo sistema de tempo de execução é o gerenciamento de memória, tanto da memória
alocada na pilha quanto da memória alocada dinamicamente. Sempre que existe, em um 
programa em C, uma chamada a +malloc+ ou +free+, o sistema de tempo de 
execução é invocado para administrar o _heap_. Na máquina virtual Java o 
sistema de tempo de execução inclui o coletor de lixo, que faz o gerenciamento 
automático da memória alocada dinamicamente. 

=== Por que estudar os compiladores?

O estudo das linguagens de programação é uma das áreas principais da ciência da
computação. Como os compiladores são, a rigor, implementações de linguagens de
programação, sua importância fica automaticamente estabelecida. As situações 
encontradas por cientistas da computação requerem algum entendimento sobre a 
implementação das linguagens que ele usa, mesmo que ele nunca implemente um
compilador em sua carreira. 

Mas há outros motivos que tornam este estudo importante e interessante. Aprender
sobre compiladores é útil, pois os algoritmos e estruturas de dados utilizados
são aplicáveis em vários outros contextos. Compreender como as linguagens são
implementadas também confere ao programador um maior conhecimento sobre elas,
e quais os custos envolvidos no uso de suas características. Isso permite tomar
melhor decisões sobre que linguagem usar para um determinado problema; um
profissional competente deve sempre, dentro das restrições apresentadas, 
escolher a melhor linguagem para cada problema. 

O estudo também é interessante do ponto de vista teórico, pois os compiladores
interagem com várias outras áreas centrais da computação, demonstrando um
ótimo exemplo de sintonia entre teoria e prática:

* *Teoria da Computação* -- Como o compilador é um programa, a teoria da 
    computação nos permite prever que tipo de análises podem ser feitas, e
    quais são possíveis mas a um custo muito alto (problema NP)
* *Linguagens Formais e Autômatos* -- Os formalismos empregados na análise 
    sintática vêm do estudo dessa área
* *Arquitetura de Computadores* -- É importante para entender as interações
    entre o código gerado e a máquina que executa o programa, e qual o 
    impacto dessas interações na eficiência do programa gerado
* *Paradigmas de programação* -- Permite entender os diferentes modelos
    semânticos utilizados nas linguagens que devem ser traduzidas

É natural esperar que poucos profissionais da área da computação precisem,
algum dia, escrever um compilador para uma linguagem de propósito geral. 
Entretanto, uma tendência atual no desenvolvimento de software é usar Linguagens 
de Domínio Específico para dividir a solução de um problema em partes gerais
e partes específicas. Como mencionado antes, o uso de LDEs traz vantagens
expressivas na criação de soluções, diminuindo a distância entre a linguagem
de programação utilizada e os conceitos do domínio do problema. Alguns 
profissionais e pesquisadores da área já propõem, hoje, um paradigma 
chamado de Programação Orientada às Linguagens (ou _Language-Oriented
Programming_, em inglês), que consiste em sempre criar linguagens específicas
para cada sistema desenvolvido. Isso enfatiza a necessidade de se educar
sobre linguagens de programação e sua implementação.

Por fim, como ferramentas que traduzem de uma linguagem para outra, os 
compiladores também são mais abrangentes do que parecem a princípio. Um exemplo 
na área de banco de dados são os programas que compilam buscas a partir de uma 
especificação SQL: eles traduzem da linguagem de consulta para um conjunto
de operações em arquivos que são as primitivas do banco de dados. Técnicas
usadas pelos compiladores também são empregadas para resolver dependências
entre equações em planilhas como Excel. Como estes, existem vários outros
exemplos, em praticamente todas as áreas da computação, onde as técnicas
estudadas nesta disciplina são utilizadas. 

=== Exemplos

GCC, etc. 


Conclusão do capítulo, considerações finais, visão geral dos próximos capítulos. 

